{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating of various Sentiment Analysis methods using Amazon Reviews\n",
    "\n",
    "#### **Objective**\n",
    "To perform sentiment analysis on Amazon product reviews using:\n",
    "1. Naive Bayes with TF-IDF vectorization.\n",
    "2. A pre-trained RoBERTa model fine-tuned on the dataset.\n",
    "\n",
    "The project aims to compare the performance of these two approaches and evaluate their trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Dataset\n",
    "There are lot of categories we can choose from the dataset. Every category has tons of review based on products. We can find the list of categories and their sizes in huggingface(https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/tree/main/raw/review_categories). First I tried using raw_review_Electronics but it takes a lot of time as the file size is more than 22GB and it took me more than 48 minutes to load the dataset to generate 43886944 examples from the dataset. To be time efficient I chose raw_review_Sports_and_Outdoors with more than 9GB filesize that took me 12 minutes to load and generate splits of 19595170 examples . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full split: 43886944 examples [35:12, 20778.11 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rating': 5.0, 'title': 'BUY THIS THANG', 'text': 'yes.. so good.  just buy it. my favorite feature is it auto connects and remembers my devices.', 'images': [], 'asin': 'B00WK47VEW', 'parent_asin': 'B017T99JPG', 'user_id': 'AGCI7FAH4GL5FI65HYLKWTMFZ2CQ', 'timestamp': 1456772365000, 'helpful_vote': 0, 'verified_purchase': True}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Electronics\", trust_remote_code=True)\n",
    "print(dataset[\"full\"][9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating full split: 19595170 examples [06:59, 46760.31 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rating': 4.0, 'title': 'Mixed feelings', 'text': 'I loved this chalk bag online, but in person, not as much - only because it seems more like a man\\'s chalk bag. It is rather large in size and the color seems darker in person. I love prAna products and enjoy their clothing line and headbands, but this definitely seems like a man\\'s chalk bag. So much so that I gifted it to a guy friend and he loves it and uses it all the time. On that note, I will say that the bag is great quality and the design is really unique. If you\\'re looking for a larger, quality chalk bag for climbing, this is a great one to own. I just wish it wasn\\'t labeled as a \"women\\'s chalk bag\", because it really is more ambiguous. Climb on!', 'images': [], 'asin': 'B001D08ZBW', 'parent_asin': 'B001D08ZBW', 'user_id': 'AGGZ357AO26RQZVRLGU4D4N52DZQ', 'timestamp': 1331692117000, 'helpful_vote': 0, 'verified_purchase': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Sports_and_Outdoors\", trust_remote_code=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.DataFrame(dataset[\"full\"])\n",
    "# Split into Train (70%), Temp (30%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split Temp into Validation (15%) and Test (15%)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print Dataset Sizes\n",
    "print(f\"Training Set: {len(train_df)}\")\n",
    "print(f\"Validation Set: {len(val_df)}\")\n",
    "print(f\"Test Set: {len(test_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
